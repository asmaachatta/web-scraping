# -*- coding: utf-8 -*-
"""scarpebarticlipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15QAkAQPjjFSgkeCS-Rxm9Cu1gzworehY
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Fetch webpage HTML
#https://www.aljazeera.net/palestine/
#https://alhudood.net/currentAffairs
#https://arabic.cnn.com/tag/palestine
url = 'https://www.aljazeera.net/palestine/'
response = requests.get(url)
html_data = response.text

# Use BeautifulSoup to find all paragraphs on the page
soup = BeautifulSoup(html_data, 'html.parser')
all_paragraphs = soup.find_all('p')

# Create a list to store the extracted paragraphs
paragraphs = []

# Extract text from each paragraph and append it to the list
for paragraph in all_paragraphs:
    text = paragraph.get_text()
    paragraphs.append(text)

# Create a DataFrame from the extracted paragraphs
df = pd.DataFrame(paragraphs, columns=['Paragraphs'])

# Print the DataFrame
print(df)

from google.colab import files

# Enregistrer le DataFrame au format CSV
df.to_csv('set_data.csv', index=False)

# Télécharger le fichier CSV dans Google Colab
files.download('set_data.csv')